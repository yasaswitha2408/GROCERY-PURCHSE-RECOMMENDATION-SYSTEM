{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19f51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c077f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"grocery_db\", \n",
    "    user=\"postgres\",        \n",
    "    password=\"1234\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f025d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from grocery_logs:\n",
      "   id item_name  quantity date_purchased    cost    supplier\n",
      "0   1      rice       100     2024-01-01  200.00  Supplier A\n",
      "1   2      milk        50     2024-01-01  100.00  Supplier B\n",
      "2   3     Bread       120     2024-10-01  150.00  Supplier C\n",
      "3   4      Eggs       200     2024-10-02  100.00  Supplier A\n",
      "4   5    Butter        80     2024-10-03  160.00  Supplier D\n",
      "\n",
      "\n",
      "Data from student_demographics:\n",
      "   student_id  home_state dietary_preference  age gender allergies\n",
      "0           1  Tamil Nadu         vegetarian   20      M      None\n",
      "1           2      Kerala     non-vegetarian   22      F   peanuts\n",
      "2           3  Tamil Nadu         Vegetarian   20      M      None\n",
      "3           4      Kerala     Non-Vegetarian   22      F   Peanuts\n",
      "4           5   Karnataka         Vegetarian   23      M      None\n",
      "\n",
      "\n",
      "Data from consumption_patterns:\n",
      "         date item_name  quantity_consumed  remaining_stock\n",
      "0  2024-01-01      Rice                 80               20\n",
      "1  2024-01-01      Milk                 40               10\n",
      "2  2024-11-01      Rice                100               50\n",
      "3  2024-11-01      Milk                 50               30\n",
      "4  2024-11-01     Bread                 80               40\n",
      "\n",
      "\n",
      "Data from events:\n",
      "   event_id             event_name  start_date    end_date  \\\n",
      "0         1   New Year Celebration  2024-01-01  2024-01-01   \n",
      "1         2             Sports Day  2024-01-05  2024-01-05   \n",
      "2         3    Guest Lecture on AI  2024-01-12  2024-01-12   \n",
      "3         4  Community Service Day  2024-01-20  2024-01-20   \n",
      "4         5         Art Exhibition  2024-01-25  2024-01-26   \n",
      "\n",
      "   expected_attendance  \n",
      "0                  300  \n",
      "1                  150  \n",
      "2                   80  \n",
      "3                  100  \n",
      "4                   70  \n",
      "\n",
      "\n",
      "Data from inventory_details:\n",
      "   id    item_name  current_stock  reorder_level last_updated\n",
      "0   1         Rice            500            100   2024-11-01\n",
      "1   2  Wheat Flour            300             50   2024-11-02\n",
      "2   3         Milk            200             30   2024-11-03\n",
      "3   4         Eggs            400            100   2024-11-04\n",
      "4   5        Sugar            150             40   2024-11-05\n",
      "\n",
      "\n",
      "Data from weather_data:\n",
      "         date  temperature weather_condition  humidity\n",
      "0  2024-11-01         25.3             Clear      60.0\n",
      "1  2024-11-02         26.1            Cloudy      62.0\n",
      "2  2024-11-03         24.5             Rainy      80.0\n",
      "3  2024-11-04         22.8     Thunderstorms      85.0\n",
      "4  2024-11-05         23.4             Clear      58.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cursor = connection.cursor()\n",
    "tables = ['grocery_logs', 'student_demographics', 'consumption_patterns', 'events', 'inventory_details', 'weather_data']\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for table in tables:\n",
    "    cursor.execute(f\"SELECT * FROM {table}\")\n",
    "    data = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]  \n",
    "    data_dict[table] = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "for table, df in data_dict.items():\n",
    "    print(f\"Data from {table}:\")\n",
    "    print(df.head()) \n",
    "    print(\"\\n\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79834180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from grocery_logs saved as CSV at C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/grocery_logs.csv.\n",
      "Data from student_demographics saved as CSV at C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/student_demographics.csv.\n",
      "Data from consumption_patterns saved as CSV at C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/consumption_patterns.csv.\n",
      "Data from events saved as CSV at C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/events.csv.\n",
      "Data from inventory_details saved as CSV at C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/inventory_details.csv.\n",
      "Data from weather_data saved as CSV at C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/weather_data.csv.\n"
     ]
    }
   ],
   "source": [
    "file_paths = {\n",
    "    \"grocery_logs\": \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/grocery_logs.csv\",\n",
    "    \"student_demographics\": \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/student_demographics.csv\",\n",
    "    \"events\": \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/events.csv\",\n",
    "    \"consumption_patterns\": \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/consumption_patterns.csv\",\n",
    "    \"inventory_details\": \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/inventory_details.csv\",\n",
    "    \"weather_data\": \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/dataset/weather_data.csv\"\n",
    "}\n",
    "for table, df in data_dict.items():\n",
    "    if table in file_paths:\n",
    "        df.to_csv(file_paths[table], index=False)\n",
    "        print(f\"Data from {table} saved as CSV at {file_paths[table]}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d741321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: grocery_logs\n",
      "Transformed and saved data for grocery_logs.\n",
      "Processing table: student_demographics\n",
      "Transformed and saved data for student_demographics.\n",
      "Processing table: consumption_patterns\n",
      "Transformed and saved data for consumption_patterns.\n",
      "Processing table: events\n",
      "Transformed and saved data for events.\n",
      "Processing table: inventory_details\n",
      "Transformed and saved data for inventory_details.\n",
      "Processing table: weather_data\n",
      "Transformed and saved data for weather_data.\n",
      "ETL process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "def clean_data(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype in ['float64', 'int64']:\n",
    "            df[column].fillna(df[column].mean(), inplace=True)\n",
    "        elif df[column].dtype == 'object':\n",
    "            df[column].fillna(\"Unknown\", inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    for column in df.columns:\n",
    "        if 'date' in column.lower():\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def enrich_data(df, table_name):\n",
    "    if table_name == 'grocery_logs':\n",
    "        df['total_cost'] = df['quantity'] * df['cost']\n",
    "        if 'date_purchased' in df.columns:\n",
    "            df['weekday'] = df['date_purchased'].dt.day_name()\n",
    "    \n",
    "    elif table_name == 'student_demographics':\n",
    "        if 'age' in df.columns:\n",
    "            df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 50, 100], labels=['Young', 'Adult', 'Middle Age', 'Senior'])\n",
    "    \n",
    "    elif table_name == 'consumption_patterns':\n",
    "        df['weekly_consumption'] = df['quantity_consumed'] * 7\n",
    "    \n",
    "    elif table_name == 'events':\n",
    "        if 'start_date' in df.columns:\n",
    "            df['event_month'] = df['start_date'].dt.month_name()\n",
    "    \n",
    "    elif table_name == 'inventory_details':\n",
    "        if 'current_stock' in df.columns and 'reorder_level' in df.columns:\n",
    "            df['needs_reorder'] = df['current_stock'] < df['reorder_level']\n",
    "    \n",
    "    elif table_name == 'weather_data':\n",
    "        if 'temperature' in df.columns:\n",
    "            df['temperature_celsius'] = (df['temperature'] - 32) * 5.0/9.0\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standardize_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    \n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[f\"{column}_standardized\"] = scaler.fit_transform(df[[column]])\n",
    "        df[f\"{column}_scaled\"] = minmax_scaler.fit_transform(df[[column]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def aggregate_data(df, table_name):\n",
    "    if table_name == 'grocery_logs':\n",
    "        return df.groupby('item_name').agg({\n",
    "            'quantity': 'sum',\n",
    "            'total_cost': 'sum'\n",
    "        }).reset_index()\n",
    "    \n",
    "    elif table_name == 'consumption_patterns':\n",
    "        return df.groupby('item_name').agg({\n",
    "            'quantity_consumed': 'sum',\n",
    "            'weekly_consumption': 'sum'\n",
    "        }).reset_index()\n",
    "    \n",
    "    elif table_name == 'inventory_details':\n",
    "        return df.groupby('item_name').agg({\n",
    "            'current_stock': 'sum'\n",
    "        }).reset_index()\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "transformed_file_path = \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/transformed/\"\n",
    "aggregated_file_path = \"C:/Users/Sweety Chittineni/Downloads/grocery recommendation system/aggregated/\"\n",
    "ensure_directory_exists(transformed_file_path)\n",
    "ensure_directory_exists(aggregated_file_path)\n",
    "\n",
    "transformed_data = {}\n",
    "for table_name, df in data_dict.items():\n",
    "    print(f\"Processing table: {table_name}\")\n",
    "    df = clean_data(df)\n",
    "    df = enrich_data(df, table_name)\n",
    "    df = standardize_data(df)\n",
    "    df_aggregated = aggregate_data(df, table_name)\n",
    "    transformed_data[table_name] = df\n",
    "    transformed_data[f\"{table_name}_aggregated\"] = df_aggregated\n",
    "    df.to_csv(f\"{transformed_file_path}{table_name}_transformed.csv\", index=False)\n",
    "    if not df_aggregated.empty:\n",
    "        df_aggregated.to_csv(f\"{aggregated_file_path}{table_name}_aggregated.csv\", index=False)\n",
    "    \n",
    "    print(f\"Transformed and saved data for {table_name}.\")\n",
    "\n",
    "print(\"ETL process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395434c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
